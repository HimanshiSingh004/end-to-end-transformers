{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Inference with the AWS Step Functions Data Science SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "import stepfunctions\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.workflow import Workflow, cloudformation\n",
    "from stepfunctions.steps import Chain, ProcessingStep, TransformStep, Catch, Fail, Succeed\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role() # execution role for SageMaker\n",
    "workflow_execution_role = role # execution role for Step Functions\n",
    "bucket = sagemaker_session.default_bucket() # you can specify a bucket name here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution input placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = uuid.uuid1().hex\n",
    "processing_input = '<your-data-s3-path>' \n",
    "processing_output= f's3://{bucket}/{job_name}/data/processed/'\n",
    "transform_input = f's3://{bucket}/{job_name}/data/processed/test_batch_transform.csv'\n",
    "transform_output = f's3://{bucket}/{job_name}/data/predicted/'\n",
    "model_artefact = '<your-model-s3-path>'\n",
    "\n",
    "execution_input = ExecutionInput(\n",
    "    schema={\n",
    "        \"JobName\": str,\n",
    "        \"Processing\": {\n",
    "            \"Input\": str,\n",
    "            \"Output\": str\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = Processor(\n",
    "    role=role, \n",
    "    image_uri='<your-container-image-uri>', \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=30, \n",
    "    max_runtime_in_seconds=1200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/opt/ml/processing/input'\n",
    "output_folder = '/opt/ml/processing/output'\n",
    "\n",
    "inputs = [\n",
    "    ProcessingInput(\n",
    "        input_name='input',\n",
    "        source=execution_input[\"Processing\"][\"Input\"],\n",
    "        destination=input_folder\n",
    "    )\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name='preprocessed',\n",
    "        source=output_folder,\n",
    "        destination=execution_input[\"Processing\"][\"Output\"]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker model and Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(model_data=model_artefact,\n",
    "                   name=name_from_base('bert-model'),\n",
    "                   role=role, \n",
    "                   entry_point='predict_batch.py',\n",
    "                   source_dir='source_dir',\n",
    "                   framework_version='1.5.0')\n",
    "\n",
    "transformer = model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge',\n",
    "    strategy='SingleRecord',\n",
    "    assemble_with='Line',\n",
    "    accept = 'text/csv',\n",
    "    max_concurrent_transforms=50,\n",
    "    output_path=transform_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define workflow steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_step = ProcessingStep(\n",
    "    state_id=\"Process Data\",\n",
    "    processor=data_processor,\n",
    "    job_name=execution_input[\"JobName\"],\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    container_arguments=[f\"--input={input_folder}\", f\"--output={output_folder}\"],\n",
    "    result_path=\"$.Processing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_step = TransformStep(\n",
    "    state_id='Predict Batch',\n",
    "    transformer=transformer,\n",
    "    job_name=execution_input['JobName'],     \n",
    "    model_name=model.name, \n",
    "    data=transform_input,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    join_source='Input',\n",
    "    result_path=\"$.Inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error catching, failure and success steps\n",
    "failed = Fail(state_id=\"Failed\")\n",
    "succeed = Succeed(state_id=\"Succeed\")\n",
    "\n",
    "catch_failures = Catch(error_equals=[\"States.ALL\"], next_step=failed)\n",
    "processing_step.add_catch(catch_failures)\n",
    "transformer_step.add_catch(catch_failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create workflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_graph = Chain([\n",
    "        processing_step,\n",
    "        transformer_step,\n",
    "        succeed\n",
    "])\n",
    "\n",
    "workflow_pipeline = Workflow(\n",
    "    name=\"BatchWorkflow\",\n",
    "    definition=workflow_graph,\n",
    "    execution_input=execution_input,\n",
    "    role=workflow_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(workflow_pipeline.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_pipeline.render_graph(portrait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/update state machine and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_pipeline.create()\n",
    "# workflow_pipeline.update(workflow_pipeline_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow pipeline inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_inputs = {\n",
    "    \"JobName\": job_name, \n",
    "    \"Processing\": {\n",
    "        \"Input\": processing_input, \n",
    "        \"Output\": processing_output\n",
    "    }\n",
    "}\n",
    "\n",
    "workflow_pipeline.execute(inputs=execution_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CloudFormation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(workflow_pipeline.get_cloudformation_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
