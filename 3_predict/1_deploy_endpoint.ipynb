{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps - NLP Lab with Amazon SageMaker\n",
    "\n",
    "**Step 3** - *Deploy your model on a SageMaker Endpoint and query it for prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "### Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract location of the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact_fname = '../2_train_model/model_artifact_location.txt'\n",
    "if os.path.exists(model_artifact_fname):\n",
    "    with open(model_artifact_fname, 'r') as f:\n",
    "        model_artefact = f.readline()\n",
    "\n",
    "    print(model_artefact)\n",
    "    \n",
    "else:\n",
    "    print(f'Model artifact location file not found ({model_artifact_fname}): check that the previous notebook was fully executed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Amazon SageMaker endpoint\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a real time predictor object to serve our model:\n",
    "class SentimentAnalysis(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, \n",
    "                         sagemaker_session=sagemaker_session, \n",
    "                         serializer=json_serializer, \n",
    "                         deserializer=json_deserializer, \n",
    "                         content_type='application/json')\n",
    "\n",
    "# Use the previously defined Predictor to build a Model:\n",
    "model = PyTorchModel(model_data=model_artefact,\n",
    "                     name=name_from_base('bert-model'),\n",
    "                     role=role,\n",
    "                     entry_point='predict_endpoint.py',\n",
    "                     source_dir='source_dir',\n",
    "                     framework_version='1.5.0',\n",
    "                     predictor_cls=SentimentAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model:\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can request prediction from our model, deployed behind the previous endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define the payload:\n",
    "test_data = {\"text\": \"I love completing my todos! Best app ever!!!\"}\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We send this payload to the endpoint:\n",
    "prediction = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And print the request and associated payload\n",
    "print(f'Review text: {test_data}')\n",
    "print(f'Sentiment  : {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to delete this endpoint or you will continue to incur cost while it's live:\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
