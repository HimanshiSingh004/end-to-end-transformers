{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps - NLP Lab with Amazon SageMaker\n",
    "\n",
    "**Step 3B** - *Predict in batch using SageMaker Batch Transform*\n",
    "## Initialization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact_fname = '../2_train_model/model_artifact_location.txt'\n",
    "if os.path.exists(model_artifact_fname):\n",
    "    with open(model_artifact_fname, 'r') as f:\n",
    "        model_artefact = f.readline()\n",
    "\n",
    "    print(model_artefact)\n",
    "    \n",
    "else:\n",
    "    print(f'Model artifact location file not found ({model_artifact_fname}): check that the previous notebook was fully executed.')\n",
    "    \n",
    "input_location_fname = '../1_prepare_data/processing_input_location.txt'\n",
    "if os.path.exists(input_location_fname):\n",
    "    with open(input_location_fname, 'r') as f:\n",
    "        processing_input = f.readline()\n",
    "\n",
    "    print(f'Processing input location | {processing_input}')\n",
    "    \n",
    "else:\n",
    "    print(f'Processing input location file not found ({input_location_fname}): check that the previous notebook was fully executed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(model_data=model_artefact,\n",
    "                   name=name_from_base('bert-model'),\n",
    "                   role=role, \n",
    "                   entry_point='predict_batch.py',\n",
    "                   source_dir='source_dir',\n",
    "                   framework_version='1.5.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch batch predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the batch transform job: don't forget to change the following paths in the cell below before execution:\n",
    "* **`<YOUR-TEST-DATA-S3-PATH>`**: location of the processing job output results\n",
    "* **`<YOUR-OUTPUT-RESULTS-S3-PATH>`**: S3 location where you want your predictions to be emitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = 's3://<YOUR-TEST-DATA-S3-PATH>/test_batch_transform.csv'\n",
    "s3_output = 's3://<YOUR-OUTPUT-RESULTS-S3-PATH>'\n",
    "\n",
    "transformer = model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge',\n",
    "    strategy='SingleRecord',\n",
    "    assemble_with='Line',\n",
    "    accept = 'text/csv',\n",
    "    max_concurrent_transforms=50,\n",
    "    output_path=s3_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request the batch predictions and wait for the process to finish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer.transform(\n",
    "    test_data,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    join_source='Input'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
